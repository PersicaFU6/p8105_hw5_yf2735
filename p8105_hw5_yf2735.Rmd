---
title: "p8105_hw5_yf2735"
author: "Yujing FU"
date: "2024-11-13"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(dplyr)
library(tidyr)
library(ggplot2)
library(broom)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1

```{r}
# Define the function
check_duplicates = function(group_size) {
  birthdays = sample(1:365, group_size, replace = TRUE)  # 365days
  return(any(duplicated(birthdays)))  # TRUE if duplicates, FALSE otherwise
}

# simulation and compute probabilities
set.seed(123) 
group_sizes = 2:50
num_simulations = 10000

results = map_dbl(group_sizes, function(size) {
  mean(replicate(num_simulations, check_duplicates(size)))
})

prob_df = data.frame(group_size = group_sizes, probability = results)


ggplot(prob_df, aes(x = group_size, y = probability)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Probability of at least two people sharing a birthday",
    x = "Group Size",
    y = "Probability"
  ) +
  theme_minimal()
```

The probability of having repeated birthday increase rapidly when the group size increase from 2 to 20. When the group size is around 25, the probability exceeds 50%. When the group size is around 50, the probability approaches to 1.

## Problem 2

```{r}
n = 30        
sigma= 5    
num_simulations = 5000
alpha = 0.05 

# different mu_values
mu_values = c(0, 1, 2, 3, 4, 5, 6)

# stimulation function
simulate_for_mu = function(mu) {
  replicate(num_simulations, {
    data = rnorm(n, mean = mu, sd = sigma)
    t_test_result = t.test(data, mu = 0) #simple sample t test
    t_test_tidy = broom::tidy(t_test_result) #turn results into df
    list(mu = mu, p_value = t_test_tidy$p.value, mu_hat = t_test_tidy$estimate)
  }, simplify = FALSE) |> 
    transpose()
}

# stimulation
results = map_dfr(mu_values, simulate_for_mu) |> 
  unnest(cols = c(p_value, mu_hat))

```

```{r}
# power of test
power_results = results |> 
  group_by(mu) |> 
  summarize(power = mean(p_value < alpha)) |>
  mutate(mu = as.numeric(unlist(mu)), power = as.numeric(unlist(power)))

# average estimate of mu_hat
mean_mu_hat = results |> 
  group_by(mu) |> 
  summarize(mean_mu_hat = mean(mu_hat))|>
  mutate(mu = as.numeric(unlist(mu)), mean_mu_hat = as.numeric(unlist(mean_mu_hat)))

# average estimate of mu_hat only in samples for which the null was rejected 
mean_mu_hat_rejected = results |> 
  filter(p_value < alpha) |> 
  group_by(mu) |> 
  summarize(mean_mu_hat_rejected = mean(mu_hat))|>
  mutate(mu = as.numeric(unlist(mu)), mean_mu_hat_rejected = as.numeric(unlist(mean_mu_hat_rejected)))

```


```{r}
# plot the power of test
ggplot(power_results, aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(title = "Power vs True Mean (μ)", x = "True Mean (μ)", y = "Power") +
  theme_minimal()
```
<br>
When true mean is small, the power is small, which means it's difficult to reject the null hypothesis. With the increase of true mean, the power of test tend to increase and approaches to 1, which means it can correctly reject the null hypothesis.


```{r}
mu_hat_results = 
  mean_mu_hat |> 
  left_join(mean_mu_hat_rejected, by = "mu")

ggplot(mu_hat_results, aes(x = mu)) +
  geom_line(aes(y = mean_mu_hat, color = "Mean Estimate (All Samples)"), linewidth = 1) +
  geom_point(aes(y = mean_mu_hat, color = "Mean Estimate (All Samples)"), size = 2) +
  geom_line(aes(y = mean_mu_hat_rejected, color = "Mean Estimate (Reject Null)"), linewidth = 1) +
  geom_point(aes(y = mean_mu_hat_rejected, color = "Mean Estimate (Reject Null)"), size = 2) +
  labs(
    title = "Average Estimate of Sample Mean (mu_hat) vs True Mean (μ)",
    x = "True Mean (μ)",
    y = "Average Estimate of Sample Mean (mu_hat)"
  ) +
  scale_color_manual(
    values = c("Mean Estimate (All Samples)" = "black", "Mean Estimate (Reject Null)" = "red"),
    name = "Legend"
  ) +
  theme_minimal()
```
<br>
The sample average of mu of all samples are approximately equal to the true value of mu. And sample average of mu across the cross tests for which the null is rejected is closer to the true value when the true mean is bigger.

## Problem 3
```{r}
homicides_raw_df = read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/refs/heads/master/homicide-data.csv")
```

```{r}
homicides_df =
  homicides_raw_df |> 
  mutate(city_state = paste(city, state, sep = ", ")) |> 
  group_by(city_state) |> 
  summarize(
    num_homicides = n(),
    num_unsolved_homicides = sum(disposition == "Open/No arrest" | disposition == "Closed without arrest", na.rm = TRUE)
  )

```

```{r}
baltimore_unsolved_df = 
  homicides_df |> 
  filter(city_state == "Baltimore, MD") 

# prop test for baltimore
baltimore_prop_test = prop.test(
  x = baltimore_unsolved_df$num_unsolved_homicides,
  n = baltimore_unsolved_df$num_homicides
)
baltimore_result = 
  broom::tidy(baltimore_prop_test) |> 
  select(estimate, conf.low, conf.high)

baltimore_result
```

```{r}
# prop test for each city
prop_test_by_city = 
  homicides_df |> 
  mutate(
    test_results = map2(
      num_unsolved_homicides,
      num_homicides,
      ~ prop.test(x = .x, n = .y) |> 
        broom::tidy()
    )
  ) |> 
  unnest(test_results) |> 
  select(city_state, estimate, conf.low, conf.high)

# estimates and CIs for each city
prop_test_by_city |> 
  ggplot(aes(
    x = reorder(city_state, estimate), 
    y = estimate
  )) +
  geom_point() +
  geom_errorbar(
    aes(ymin = conf.low, ymax = conf.high), 
    width = 0.2
  ) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Proportion of Unsolved Homicides"
  )+
  theme(axis.text.y = element_text(size = 4.5))
```

